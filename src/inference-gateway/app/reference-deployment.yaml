apiVersion: apps/v1
kind: Deployment
metadata:
  name: <MODEL-NAME>-inference-server
  namespace: model-pipeline
spec:
  replicas: 1
  selector:
    matchLabels:
      app: <MODEL-NAME>-inference-server
  template:
    metadata:
      labels:
        app: <MODEL-NAME>-inference-server
    spec:
      containers:
        - name: <MODEL-NAME>-inference-server
          image: icantkube/model-inference-server:v0.24
          ports:
            - containerPort: 80
          env:
            - name: MODEL_NAME
              value: "Wittman"
            - name: PREDICTION_INTERVAL
              value: "5"
          envFrom:
            - secretRef:
                name: mlflow-credentials-secret
            - configMapRef:
                name: mlflow-server-link-config
                